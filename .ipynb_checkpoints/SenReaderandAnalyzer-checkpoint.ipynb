{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A4KWz1YIVfVz"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24282,
     "status": "ok",
     "timestamp": 1556381850277,
     "user": {
      "displayName": "Michael Dendinger",
      "photoUrl": "https://lh6.googleusercontent.com/-k4mVZ8txeng/AAAAAAAAAAI/AAAAAAAAGQY/DGNX_VENvSY/s64/photo.jpg",
      "userId": "07534567184190262751"
     },
     "user_tz": 360
    },
    "id": "o86JUvgQlfLI",
    "outputId": "3371c740-4af4-4389-ad2d-8f0dfefe88dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bRgHS1GDVyUG"
   },
   "outputs": [],
   "source": [
    "# #cassidy has been the test file I have been using\n",
    "# billcassidy = pd.read_csv(\"CheckThese.csv\")\n",
    "\n",
    "!ls \"drive/My Drive/Senator/Tweet CSVs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 975,
     "status": "ok",
     "timestamp": 1556382226477,
     "user": {
      "displayName": "Michael Dendinger",
      "photoUrl": "https://lh6.googleusercontent.com/-k4mVZ8txeng/AAAAAAAAAAI/AAAAAAAAGQY/DGNX_VENvSY/s64/photo.jpg",
      "userId": "07534567184190262751"
     },
     "user_tz": 360
    },
    "id": "vKmgsIjhnAyr",
    "outputId": "ad3fcb61-62ea-4d5a-eb60-b0006f19920b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loadCSV(filePath):\n",
    "    dataframe = pd.read_csv(filePath, encoding='iso-8859-1')\n",
    "    dataframe.columns = ['id', 'date', 'text', 'rating']\n",
    "    #datakeys = dataframe.keys();\n",
    "    return dataframe\n",
    "\n",
    "tweet_training_file = loadCSV('drive/My Drive/Senator/Training Docs/SelfMadeSentimentTrainerTest.csv') #this is from the stanford example, but I need to update the files \n",
    "type(tweet_training_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PAvDZFWynFqp"
   },
   "outputs": [],
   "source": [
    "for data, information in tweet_training_file.iterrows():\n",
    "  print(information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KkVP4gFwnM59"
   },
   "outputs": [],
   "source": [
    "#this one leads the file to read the tweet\n",
    "train_documents = [line[2] for data, line in tweet_training_file.iterrows()] \n",
    "\n",
    "#this one reads the sentiment rating\n",
    "train_labels = [int(line[3]) for data, line in tweet_training_file.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "emRDczq_nTnF"
   },
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(binary=\"false\")\n",
    "train_documents = count_vectorizer.fit_transform(train_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_ngBj4iMnXI6"
   },
   "outputs": [],
   "source": [
    "#currently using Bernoulli, may want to look into using different methods. Jeff said it may be a good idea\n",
    "classifier = BernoulliNB().fit(train_documents, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4G3G80YjnfAa"
   },
   "outputs": [],
   "source": [
    "def predictionOutput(sentence):\n",
    "    prediction = classifier.predict(count_vectorizer.transform([sentence]))\n",
    "    if(prediction[0] == 2):\n",
    "        #print(\"Positive\")\n",
    "        sentiment.append(\"Positive\")\n",
    "    elif (prediction[0] == 1):\n",
    "        #print(\"Neutral\")\n",
    "        sentiment.append(\"Neutral\")\n",
    "    elif (prediction[0] == 0):\n",
    "        #print(\"Negative\")\n",
    "        sentiment.append(\"Negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 348682,
     "status": "ok",
     "timestamp": 1556383687200,
     "user": {
      "displayName": "Michael Dendinger",
      "photoUrl": "https://lh6.googleusercontent.com/-k4mVZ8txeng/AAAAAAAAAAI/AAAAAAAAGQY/DGNX_VENvSY/s64/photo.jpg",
      "userId": "07534567184190262751"
     },
     "user_tz": 360
    },
    "id": "7rx8Cl9AmBRK",
    "outputId": "54238c46-dae2-4b26-b570-3036bb110cb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299200\n",
      "299200\n",
      "299200\n"
     ]
    }
   ],
   "source": [
    "path = r'drive/My Drive/Senator/Tweet CSVs' # use your path\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "senator = []\n",
    "senators_tweet = []\n",
    "sentiment = []\n",
    "\n",
    "for file_ in all_files:\n",
    "  file_df = pd.read_csv(file_, parse_dates=[0], infer_datetime_format=True,header=None )\n",
    "  for data, tweet in file_df.iterrows():\n",
    "    senator.append(file_)\n",
    "    senators_tweet.append(tweet[2])\n",
    "    predictionOutput(tweet[2])\n",
    "  #file_df['sentiment'] = \n",
    "  #file_df['file_name'] = file_\n",
    "  #df = df.append(file_df)\n",
    "\n",
    "print(len(senator))\n",
    "print(len(senators_tweet))\n",
    "print(len(sentiment))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o0fV0cflst5u"
   },
   "outputs": [],
   "source": [
    "\n",
    "zip_list = zip(senator,senators_tweet,sentiment)\n",
    "import csv\n",
    "csvfile = \"example.csv\"\n",
    "with open(csvfile, \"w\") as output:\n",
    "  writer = csv.writer(output, lineterminator='\\n')\n",
    "  for line in zip_list:\n",
    "    senatorname = line[0]\n",
    "    senatortweet = line[1]\n",
    "    sentimentoftweet = line[2]\n",
    "    writer.writerow([senatorname, senatortweet, sentimentoftweet])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m-Y56xbEVy1b"
   },
   "outputs": [],
   "source": [
    "# billcassidy\n",
    "# almost_tweets =[]\n",
    "# closer_tweets = []\n",
    "# test_tweets = []\n",
    "\n",
    "# #this section needs to be fixed. I am trying to change all the UTF8 issues. \n",
    "\n",
    "# for data, tweet in billcassidy.iterrows():\n",
    "#   tweets = tweet[2]\n",
    "#   almost_tweets.append(tweets)\n",
    "  \n",
    "# for sayings in almost_tweets:\n",
    "#   closer_tweets.append(sayings.replace('\\\\xe2\\\\x80\\\\xa6', ''))\n",
    "  \n",
    "# for rackets in closer_tweets:\n",
    "#     test_tweets.append(rackets.replace('\\\\xe2\\\\x80\\\\x99', \"\"))\n",
    "\n",
    "\n",
    "  \n",
    "# test_tweets\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9nEaJS2gKC1g"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "SenReaderandAnalyzer.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
